# ğŸ›’ Capturador automÃ¡tico de precios

Se trata de una aplicaciÃ³n que automatiza la extracciÃ³n, procesamiento y visualizaciÃ³n de precios de productos veganos de 3 marcas lÃ­deres (NotCo, Vegetalex y Felices las Vacas) en 6 de los principales supermercados de Argentina.  
Su objetivo es brindar **transparencia frente a la dispersiÃ³n de precios**, detectar **oportunidades de ahorro** y permitir un anÃ¡lisis **rÃ¡pido e interactivo**.

---

## ğŸ“Š CaracterÃ­sticas principales

- ğŸ§¾ **Scraping automatizado** de sitios de supermercados  
- ğŸ§¹ **UnificaciÃ³n y limpieza de datos histÃ³ricos**  
- ğŸ“ˆ **Dashboard interactivo** desarrollado con Streamlit  
- ğŸ” **GrÃ¡ficos de evoluciÃ³n** y **tabla dinÃ¡mica** con resaltado de precios mÃ­nimos y mÃ¡ximos  
- ğŸ¯ **Filtros por marca y fecha** para anÃ¡lisis especÃ­ficos  
- ğŸ’¸ **Tarjetas de oportunidades** que muestran el supermercado con el precio mÃ¡s bajo disponible

---

## ğŸ— Arquitectura y stack tecnolÃ³gico

### ğŸ•¸ Scraping
- **Python 3.9+**
- `Playwright` para navegaciÃ³n y extracciÃ³n automatizada
- `GitHub Actions` para ejecuciÃ³n periÃ³dica con `cron`

### ğŸ§ª Procesamiento de datos
- `pandas` para limpieza, transformaciÃ³n y consolidaciÃ³n de datos
- `FuzzyWuzzy` para normalizaciÃ³n de nombres de productos
- `glob` y `os` para manejo de archivos

### ğŸ“Š VisualizaciÃ³n
- `Streamlit` para la interfaz web interactiva
- `DataFrame Styler` para formato de tablas con resaltado de precios
- GrÃ¡ficos generados con pandas y componentes nativos de Streamlit

### âš™ï¸ CI/CD y despliegue
- `GitHub Actions` para orquestar scraping, procesamiento y actualizaciÃ³n
- Hosting en `Streamlit Cloud` (o alternativamente en `Heroku`) con despliegue automÃ¡tico

---

## ğŸ“‚ Estructura del repositorio

Data/
â”œâ”€â”€ Raw/ # Archivos brutos descargados del scraping
â””â”€â”€ Cleaned/ # CSVs listos para usar en el dashboard

scrape_all_async_v2.py # Script principal de scraping
unify_product_names.py # NormalizaciÃ³n de nombres con FuzzyWuzzy
dashboard.py # App principal en Streamlit
requirements.txt # Dependencias
.github/workflows/ # Jobs de CI/CD para scraping y despliegue

yaml
Copiar
Editar

---

## ğŸš€ GuÃ­a rÃ¡pida de instalaciÃ³n y uso

### 1. Clonar el repositorio
```bash
git clone https://github.com/ASzklar/price-scraper.git
cd price-scraper
2. Crear entorno virtual e instalar dependencias
bash
Copiar
Editar
python -m venv .venv
source .venv/bin/activate        # macOS/Linux
# .venv\Scripts\activate         # Windows

pip install --upgrade pip
pip install -r requirements.txt
python -m playwright install --with-deps
3. Ejecutar scraping y procesamiento
bash
Copiar
Editar
python scrape_all_async_v2.py
python unify_product_names.py
4. Iniciar el dashboard localmente
bash
Copiar
Editar
streamlit run dashboard.py
ğŸ‘‰ Luego abrÃ­ tu navegador en: http://localhost:8501

ğŸ“ˆ Contexto: DispersiÃ³n de precios en Argentina
En el mercado argentino, los precios de alimentos pueden variar hasta un 30â€“40â€¯% entre supermercados para un mismo producto. Factores como ubicaciÃ³n, stock o promociones hacen difÃ­cil saber cuÃ¡l es realmente la mejor oferta.

Este proyecto permite visualizar cÃ³mo cambian los precios a lo largo del tiempo y entre cadenas, facilitando la comparaciÃ³n y ayudando a los consumidores a tomar mejores decisiones.

ğŸ¤ CÃ³mo contribuir
HacÃ© fork del repositorio

CreÃ¡ una rama: git checkout -b feature/nueva-caracteristica

Commit de tus cambios: git commit -m "Agrega X"

Push a tu fork: git push origin feature/nueva-caracteristica

AbrÃ­ un Pull Request describiendo tu aporte

ğŸ“„ Licencia
Este proyecto estÃ¡ bajo licencia MIT. Para mÃ¡s detalles, consultÃ¡ el archivo LICENSE.
